# ü§ñ Instrucciones Cr√≠ticas para Agente de Codificaci√≥n

## Prop√≥sito de este Documento

Este documento contiene **restricciones arquitect√≥nicas y principios de dise√±o inmutables** que CUALQUIER agente de codificaci√≥n que implemente Rumbo SUP **DEBE respetar**.

Estas reglas existen para evitar que el agente:
- Simplifique indebidamente la l√≥gica
- Colapse la separaci√≥n Layer A / Layer B
- Mezcle explicaci√≥n con decisi√≥n
- Cree un "sem√°foro GO/NO-GO" gen√©rico

> [!CAUTION]
> **Si un agente viola estas reglas, el sistema perder√° su prop√≥sito educativo y de seguridad.**

---

## üö® Reglas Inmutables (NUNCA Violar)

### Regla 1: Layer A y Layer B Nunca Se Mezclan

#### Layer A (Motor Determin√≠stico)
- **Responsabilidad**: Calcular scores de seguridad, esfuerzo y disfrute
- **M√©todo**: Algoritmos determin√≠sticos, umbrales definidos, reglas formales
- **Salida**: N√∫meros y categor√≠as (sin explicaci√≥n en lenguaje natural)
- **NO puede**: Usar IA, tomar decisiones subjetivas, cambiar basado en feedback

#### Layer B (Sistema Pedag√≥gico)
- **Responsabilidad**: Explicar los resultados del Layer A en lenguaje educativo
- **M√©todo**: LLM (Gemini/GPT) con prompts estructurados
- **Salida**: Texto educativo, glosario, checklists visuales
- **NO puede**: Calcular scores, decidir si es seguro, contradecir Layer A

#### ‚ö†Ô∏è Implementaci√≥n

```python
# ‚ùå MAL - Layer B influye en decisi√≥n
def analyze_conditions(weather, user):
    # Pregunta a LLM si es seguro
    ai_result = gemini.ask("¬øEs seguro remar con viento de 25 km/h?")
    return parse_ai_decision(ai_result)

# ‚úÖ BIEN - Layer A decide, Layer B explica
def analyze_conditions(weather, user):
    # Layer A: C√°lculo determin√≠stico
    engine = SenseiEngine()
    result = engine.analyze(weather, spot, user)  # Pure logic
    
    # Layer B: Explicaci√≥n (separada, nunca influye en result)
    explanation = pedagogy_service.explain(result, weather, user)
    
    return result, explanation
```

**Test de violaci√≥n**: Si borras el LLM, ¬øel sistema sigue decidiendo correctamente? ‚Üí Debe ser S√ç.

---

### Regla 2: Sem√°foro = SOLO Seguridad (Nunca GO/NO-GO)

#### Prohibido
- Texto "GO" o "NO-GO" en el indicador circular
- Colapsar riesgo + esfuerzo + disfrute en un solo score
- Dar una "recomendaci√≥n final"

#### Obligatorio
- Indicador circular muestra **solo seguridad**
- Textos permitidos:
  - Verde: "Condiciones seguras"
  - Amarillo: "Con precauci√≥n"
  - Rojo: "No recomendado"
- Cards separadas para esfuerzo y disfrute

#### Razonamiento
Alguien puede querer:
- Entrenar fuerte (alto esfuerzo) en condiciones seguras ‚úÖ
- Relajarse (bajo esfuerzo) en condiciones seguras ‚úÖ

NO puede querer:
- Alto riesgo aunque disfrute sea alto ‚ùå

Por eso: **Seguridad es no-negociable, esfuerzo/disfrute son preferencias.**

#### ‚ö†Ô∏è Implementaci√≥n

```jsx
// ‚ùå MAL - GO/NO-GO colapsa todo
<SecurityIndicator>
  {overallScore > 70 ? "GO" : "NO-GO"}
</SecurityIndicator>

// ‚úÖ BIEN - Solo seguridad + cards separadas
<SecurityIndicator security={result.scores.seguridad}>
  {security > 70 ? "Condiciones seguras" : "..."}
</SecurityIndicator>

<MetricCard label="Esfuerzo" value={result.scores.esfuerzo} />
<MetricCard label="Disfrute" value={result.scores.disfrute} />
```

---

### Regla 3: Disfrute NO es Inverso de Riesgo

#### Prohibido
```python
# ‚ùå Simplificaci√≥n incorrecta
disfrute = 100 - riesgo - esfuerzo
```

#### Obligatorio
Disfrute se calcula seg√∫n **adecuaci√≥n a objetivo de sesi√≥n**:

```python
def calculate_enjoyment(weather, session_goal, experience):
    """
    session_goal: 'calma' | 'entrenamiento' | 'desaf√≠o'
    """
    if session_goal == 'calma':
        # Prefiere condiciones suaves
        if weather.wind < 15 and weather.waves < 1.0:
            return 80  # Alto disfrute
        else:
            return 30  # Bajo disfrute
    
    elif session_goal == 'entrenamiento':
        # Prefiere condiciones moderadas que desaf√≠en sin abrumar
        if moderate_conditions_for_skill_level(weather, experience):
            return 85
        else:
            return 50
    
    elif session_goal == 'desaf√≠o':
        # Avanzados disfrutan condiciones exigentes (pero seguras)
        if challenging_but_safe(weather, experience):
            return 90
        else:
            return 40
```

**Mismo mar, 3 objetivos diferentes, 3 scores de disfrute diferentes.**

---

### Regla 4: LLM Output Debe Tener Estructura Forzada

#### Prohibido
- Prompts abiertos tipo "Explica las condiciones"
- Permitir que el LLM genere formato libre
- Salidas sin restricci√≥n de longitud

#### Obligatorio
```python
EXPLANATION_TEMPLATE = """
Genera una explicaci√≥n educativa siguiendo EXACTAMENTE esta estructura:

## ¬øQu√© est√° pasando?
[Descripci√≥n objetiva de las condiciones actuales en 2-3 oraciones]

## C√≥mo se siente esto
[Explicaci√≥n sensorial de la experiencia esperada: viento en la cara, estabilidad de la tabla, etc.]

## Consejos de seguridad
[3 tips espec√≠ficos y accionables]

## Checklist visual
1. [Cosa concreta para observar antes de entrar]
2. [Cosa concreta para observar antes de entrar]
3. [Cosa concreta para observar antes de entrar]

Restricciones:
- Longitud m√°xima: 300 palabras
- Tono: Amigable, educativo
- Nivel: {user_experience}
- NUNCA uses palabras "entra", "no entres", "ve", "qu√©date" - solo educa
"""
```

#### Validaci√≥n Post-Generaci√≥n
```python
def validate_explanation(text):
    required_sections = [
        "## ¬øQu√© est√° pasando?",
        "## C√≥mo se siente esto",
        "## Consejos de seguridad",
        "## Checklist visual"
    ]
    
    for section in required_sections:
        if section not in text:
            raise ValueError(f"Missing section: {section}")
    
    if len(text.split()) > 350:
        raise ValueError("Explanation too long")
    
    forbidden_words = ["entra", "no entres", "ve al agua", "qu√©date"]
    if any(word in text.lower() for word in forbidden_words):
        raise ValueError("Explanation contains decision language")
```

---

### Regla 5: Confianza es Output Formal, No Metadata

#### Prohibido
```python
# ‚ùå Confianza como metadata t√©cnica
def analyze():
    result = calculate_scores()
    result.metadata = {"confidence": "high" if all_data_present else "low"}
```

#### Obligatorio
```python
# ‚úÖ Confianza como output formal del motor
def analyze(weather, spot, user):
    scores = calculate_scores(weather, user)
    
    # C√°lculo formal de confianza
    confidence_score = 100
    
    # Completitud de datos
    if weather.missing_variables:
        confidence_score -= 30
    
    # Cercan√≠a temporal
    data_age_hours = (now - weather.timestamp).hours
    if data_age_hours > 3:
        confidence_score -= 20
    
    # Volatilidad detectada
    if detect_rapid_wind_change(weather.history):
        confidence_score -= 25
    
    confidence_level = (
        "alta" if confidence_score > 70 
        else "media" if confidence_score > 40 
        else "baja"
    )
    
    return EngineResult(
        scores=scores,
        confidence=confidence_level,  # Parte del resultado principal
        confidence_factors={  # Detalles para UX
            "data_completeness": ...,
            "data_freshness": ...,
            "volatility": ...
        }
    )
```

**UX debe mostrar confianza baja expl√≠citamente** (badge o alert).

---

### Regla 6: Modelo de Seguridad es Inmutable

#### Prohibido
Cualquier ajuste del modelo de seguridad basado en:
- Feedback del usuario
- Preferencias personales
- Historial de sesiones

#### Permitido
Ajustar basado en feedback:
- **Esfuerzo**: Si usuario reporta esfuerzo menor al predicho ‚Üí incrementar "potencia de remada" en perfil
- **Disfrute**: Si usuario reporta bajo disfrute ‚Üí ajustar preferencia de objetivo

```python
def process_post_session_feedback(predicted, actual, user_profile):
    # ‚úÖ BIEN - Ajustar modelado de esfuerzo
    if actual.effort < predicted.effort - 20:
        user_profile.paddle_power = increase_one_level(user_profile.paddle_power)
    
    # ‚úÖ BIEN - Ajustar preferencias de disfrute
    if actual.enjoyment < predicted.enjoyment - 20:
        user_profile.preferred_session_goal = adjust_preference()
    
    # ‚ùå PROHIBIDO - Ajustar modelo de seguridad
    # if actual.felt_safe and predicted.security == "bajo":
    #     adjust_safety_thresholds()  # NUNCA
```

**Razonamiento**: La seguridad es objetiva. El esfuerzo y disfrute son subjetivos.

---

### Regla 7: Proveedor de Datos Meteorol√≥gicos Debe Estar Abstra√≠do

#### Prohibido
```python
# ‚ùå Acoplamiento directo a OpenMeteo
def get_weather(lat, lon):
    url = "https://marine-api.open-meteo.com/v1/marine"
    response = requests.get(url, params=...)
    return parse_openmeteo_response(response)

def analyze(lat, lon, user):
    weather = get_weather(lat, lon)  # Directamente acoplado
    return engine.analyze(weather, user)
```

#### Obligatorio
```python
# ‚úÖ Adapter pattern
from abc import ABC, abstractmethod

class WeatherProvider(ABC):
    @abstractmethod
    def get_conditions(self, lat: float, lon: float) -> WeatherData:
        pass

class OpenMeteoProvider(WeatherProvider):
    def get_conditions(self, lat, lon):
        # Implementaci√≥n espec√≠fica OpenMeteo
        pass

class StormglassProvider(WeatherProvider):
    def get_conditions(self, lat, lon):
        # Implementaci√≥n futura
        pass

# Inyecci√≥n de dependencia
class WeatherService:
    def __init__(self, provider: WeatherProvider):
        self.provider = provider
    
    def get_current_conditions(self, lat, lon):
        return self.provider.get_conditions(lat, lon)

# Uso
weather_service = WeatherService(OpenMeteoProvider())
```

**Beneficio**: Facilita swap de proveedores, agregar m√∫ltiples fuentes, testing.

---

## üéì Principios HAX (Human-AI Experience)

### Entrenamiento Perceptivo

El sistema debe **reducir dependencia del usuario con el tiempo**, no incrementarla.

#### ¬øC√≥mo?
- **Checklists visuales**: "Mir√° si las olas rompen de forma consistente"
- **Explicaciones corporales**: "Sentir√°s el viento empuj√°ndote hacia..."
- **Glosario activo**: Cada t√©rmino t√©cnico debe tener tooltip

#### Implementaci√≥n
```python
# En configuraci√≥n de spot
SPOTS = {
    "varese": {
        ...,
        "visual_checklist": [
            "Mir√° las olas cerca de la costa: ¬ørompen de forma consistente?",
            "Observ√° la espuma: ¬øse desplaza r√°pido hacia el mar?",
            "Revis√° las banderas: ¬øest√°n estiradas por el viento?"
        ]
    }
}

# En prompt de LLM
context += f"""
Incluye en la secci√≥n "Checklist visual" referencias a:
{spot.visual_checklist}
"""
```

### Feedback Loop Adaptativo

Post-sesi√≥n, el sistema debe preguntar:
- "¬øC√≥mo estuvo el esfuerzo?" (slider 1-10)
- "¬øDisfrutaste?" (slider 1-10)
- "Notas adicionales" (texto libre)

Y ajustar perfil (NO modelo de seguridad).

---

## üß™ Tests de Validaci√≥n Arquitect√≥nica

### Test 1: Independencia del LLM
```bash
# Deshabilitar LLM
export GEMINI_API_KEY=""

# El sistema debe seguir funcionando
curl POST /api/analyze
# ‚úÖ Debe retornar scores correctos
# ‚ùå Si falla, Layer A depende de Layer B (violaci√≥n)
```

### Test 2: Consistencia de Seguridad
```python
# Mismo input, mismo output (determinismo)
result1 = engine.analyze(weather, spot, user)
result2 = engine.analyze(weather, spot, user)

assert result1.scores.seguridad == result2.scores.seguridad
# ‚úÖ Debe pasar
# ‚ùå Si falla, motor es no-determin√≠stico (violaci√≥n)
```

### Test 3: Variabilidad de Disfrute
```python
# Mismo weather, diferentes objetivos, diferentes scores
result_calma = engine.analyze(weather, spot, user_calma)
result_desafio = engine.analyze(weather, spot, user_desafio)

assert result_calma.scores.disfrute != result_desafio.scores.disfrute
# ‚úÖ Debe pasar (modelado sofisticado)
# ‚ùå Si no var√≠a, disfrute es simplificado incorrectamente
```

### Test 4: Estructura de Explicaci√≥n
```python
explanation = pedagogy.explain(result, weather, user)

required_sections = ["## ¬øQu√© est√° pasando?", "## C√≥mo se siente esto", ...]
for section in required_sections:
    assert section in explanation
# ‚úÖ Debe pasar
# ‚ùå Si falla, LLM no est√° forzado a estructura
```

### Test 5: Inmutabilidad de Seguridad
```python
# Feedback no debe cambiar modelo de seguridad
original_safety = engine.analyze(weather, spot, user).scores.seguridad

process_feedback(session_id, {"felt_safe": True})

new_safety = engine.analyze(weather, spot, user).scores.seguridad

assert original_safety == new_safety
# ‚úÖ Debe pasar
# ‚ùå Si cambia, seguridad es mutable (violaci√≥n cr√≠tica)
```

---

## üìã Checklist para Agente Durante Implementaci√≥n

Antes de considerar una feature "completa", verificar:

### Motor (Layer A)
- [ ] `seguridad` (no `riesgo`) est√° invertido correctamente
- [ ] `disfrute` usa objetivo de sesi√≥n, no solo inverso de riesgo/esfuerzo
- [ ] `confianza` se calcula formalmente (completitud, temporal, volatilidad)
- [ ] Todas las reglas son determin√≠sticas (no usan LLM)
- [ ] Proveedor meteorol√≥gico est√° abstra√≠do (adapter pattern)

### Pedagog√≠a (Layer B)
- [ ] Prompt fuerza estructura (4 secciones obligatorias)
- [ ] Longitud m√°xima enforced (300 palabras)
- [ ] Validaci√≥n post-generaci√≥n rechaza "entra"/"no entres"
- [ ] Checklist visual incluida en output
- [ ] Glosario de t√©rminos est√° disponible

### Frontend
- [ ] Indicador circular dice "Condiciones seguras" (no "GO")
- [ ] Seguridad, esfuerzo, disfrute est√°n en cards SEPARADAS
- [ ] Selector de objetivo de sesi√≥n presente (calma/entrenamiento/desaf√≠o)
- [ ] Confianza baja se muestra visualmente (badge/alert)
- [ ] P√°gina PostSession implementada (feedback loop)
- [ ] Bot√≥n "Salir del agua" presente en Landing

### Integraci√≥n
- [ ] Test de independencia LLM pasa
- [ ] Test de determinismo pasa
- [ ] Test de variabilidad de disfrute pasa
- [ ] Test de estructura de explicaci√≥n pasa
- [ ] Test de inmutabilidad de seguridad pasa

---

## üö´ Anti-Patterns Comunes de Agentes

### 1. Simplificaci√≥n Prematura
```python
# ‚ùå Agente puede intentar
disfrute = 100 - riesgo  # "M√°s simple"

# ‚úÖ Debe implementar l√≥gica completa
disfrute = calculate_enjoyment_based_on_session_goal(...)
```

### 2. Colapso de Capas
```python
# ‚ùå Agente puede mezclar
def analyze_and_explain(weather):
    # LLM genera scores Y explicaci√≥n
    return gemini.ask("Analiza y explica estos datos...")

# ‚úÖ Separaci√≥n estricta
def analyze(weather):
    return engine.calculate(weather)  # Layer A

def explain(result):
    return pedagogy.generate(result)  # Layer B
```

### 3. "Smart Defaults" que Violan Principios
```python
# ‚ùå Agente puede proponer
# "Por defecto, mostrar GO/NO-GO es m√°s simple"

# ‚úÖ Debe respetar
# Sem√°foro = solo seguridad, siempre
```

### 4. Omitir Validaciones
```python
# ‚ùå Agente puede omitir por velocidad
explanation = llm.generate(prompt)
return explanation  # Sin validar

# ‚úÖ Debe validar siempre
explanation = llm.generate(prompt)
validate_structure(explanation)  # Forzar
return explanation
```

---

## üí¨ Comunicaci√≥n con Usuario Durante Implementaci√≥n

Si el agente descubre ambig√ºedad o conflicto, debe preguntar al usuario:

**Buena pregunta**:
> "La regla de viento offshore para tabla inflable actualmente suma +50 a riesgo. ¬øEs conservador suficiente o deber√≠a ser +70?"

**Mala pregunta**:
> "¬øQuieres que simplifique el modelo de disfrute? Podr√≠a ser inverso de riesgo."

**Respuesta correcta**: "No, el modelo de disfrute debe ser basado en objetivos de sesi√≥n (ver specs)."

---

## üìö Referencias

- `abstraction.md`: An√°lisis del proyecto original
- `project_prompt.md`: Especificaciones completas
- `implementation_plan.md`: Fases y componentes

---

**√öltimo recordatorio para el agente**:

> Si alguna vez tienes dudas sobre si est√°s violando una regla, pregunta al usuario. Pero si la regla est√° expl√≠cita aqu√≠, **no hay negociaci√≥n**: debe cumplirse.
